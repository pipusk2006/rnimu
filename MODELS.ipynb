{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a59bd037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import os, re, math, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from biom import load_table\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GroupShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "# === Фолдеры, классы ===\n",
    "DATA_DIRS = {\n",
    "    \"agricultural\": \"biom_data/agricultural\",\n",
    "    \"desert\":       \"biom_data/desert\",\n",
    "    \"forest\":       \"biom_data/forest\",\n",
    "    \"grassland\":    \"biom_data/grassland\",\n",
    "    \"tropical_rainforest\": \"biom_data/tropical_rainforest\",\n",
    "}\n",
    "\n",
    "# === Пороговые параметры отбора фич ===\n",
    "PREVALENCE_MIN     = 0.02       # мин. доля сэмплов класса, где таксон встречается (для CAP — считаем по train!)\n",
    "MEAN_ABUND_MIN     = 1e-5       # мин. средняя ненулевая относительная абунданса (по train)\n",
    "CAP_MAX_FEATURES   = 5000       # глобальный \"потолок\" числа фич после CAP-фильтра (по train)\n",
    "MIN_CLASS_PREV     = 0.05       # мин. доля встречаемости внутри класса (по train)\n",
    "TOP_PER_CLASS      = 300        # сколько топ таксонов брать на класс (по train)\n",
    "K_TOTAL            = 1500       # итоговый потолок признаков после MI-ужатия (по train)\n",
    "\n",
    "TEST_SIZE          = 0.20\n",
    "\n",
    "# Модели\n",
    "MODELS = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=2000, n_jobs=None, random_state=RANDOM_STATE, C=1.0),\n",
    "    \"RF\":     RandomForestClassifier(n_estimators=400, max_depth=None, random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    \"SVMrbf\": SVC(C=2.0, gamma=\"scale\", probability=True, random_state=RANDOM_STATE),\n",
    "    \"KNN5\":   KNeighborsClassifier(n_neighbors=5),\n",
    "    \"GBC\":    GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d2d55cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файлов: 598\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>file</th>\n",
       "      <th>file_stem</th>\n",
       "      <th>n_obs</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agricultural</td>\n",
       "      <td>agricultural_1.biom</td>\n",
       "      <td>agricultural_1</td>\n",
       "      <td>274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agricultural</td>\n",
       "      <td>agricultural_10.biom</td>\n",
       "      <td>agricultural_10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agricultural</td>\n",
       "      <td>agricultural_100.biom</td>\n",
       "      <td>agricultural_100</td>\n",
       "      <td>686</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agricultural</td>\n",
       "      <td>agricultural_11.biom</td>\n",
       "      <td>agricultural_11</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agricultural</td>\n",
       "      <td>agricultural_12.biom</td>\n",
       "      <td>agricultural_12</td>\n",
       "      <td>313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          class                   file         file_stem  n_obs  n_samples\n",
       "0  agricultural    agricultural_1.biom    agricultural_1    274          1\n",
       "1  agricultural   agricultural_10.biom   agricultural_10     10          1\n",
       "2  agricultural  agricultural_100.biom  agricultural_100    686          1\n",
       "3  agricultural   agricultural_11.biom   agricultural_11     19          1\n",
       "4  agricultural   agricultural_12.biom   agricultural_12    313          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма all_data: (12089, 598)\n"
     ]
    }
   ],
   "source": [
    "def load_biom_table(path):\n",
    "    table = load_table(path)\n",
    "    df = table.to_dataframe(dense=True)  # rows: obs, cols: samples\n",
    "    # нормализуем имена\n",
    "    df.index = df.index.astype(str)\n",
    "    df.columns = df.columns.astype(str)\n",
    "    return df\n",
    "\n",
    "all_mats = []\n",
    "meta_rows = []\n",
    "\n",
    "for cls, folder in DATA_DIRS.items():\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"⚠️ Нет папки: {folder}\")\n",
    "        continue\n",
    "    for fn in sorted(os.listdir(folder)):\n",
    "        if not fn.endswith(\".biom\"):\n",
    "            continue\n",
    "        file_path = os.path.join(folder, fn)\n",
    "        tbl = load_biom_table(file_path)\n",
    "        n_obs, n_samp = tbl.shape\n",
    "        file_stem = os.path.splitext(fn)[0]\n",
    "        # добавим префикс к именам сэмплов: Class:FileStem:SampleId\n",
    "        cols_map = {c: f\"{cls}:{file_stem}:{c}\" for c in tbl.columns}\n",
    "        tbl.rename(columns=cols_map, inplace=True)\n",
    "\n",
    "        all_mats.append(tbl)\n",
    "        meta_rows.append({\n",
    "            \"class\": cls,\n",
    "            \"file\": fn,\n",
    "            \"file_stem\": file_stem,\n",
    "            \"n_obs\": n_obs,\n",
    "            \"n_samples\": n_samp\n",
    "        })\n",
    "\n",
    "summary = pd.DataFrame(meta_rows)\n",
    "print(\"Файлов:\", len(summary))\n",
    "display(summary.head())\n",
    "\n",
    "# таксоны × сэмплы (объединяем по таксонам)\n",
    "all_data = pd.concat(all_mats, axis=1).fillna(0.0)\n",
    "all_data = all_data.groupby(all_data.index).sum()\n",
    "print(\"Форма all_data:\", all_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "83db16a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классы (всего): {'forest': 200, 'agricultural': 100, 'grassland': 100, 'tropical_rainforest': 100, 'desert': 98}\n",
      "Групп (file_stem): 598\n"
     ]
    }
   ],
   "source": [
    "# суммы по сэмплам\n",
    "sample_sums = all_data.sum(axis=0)\n",
    "sample_sums[sample_sums == 0] = 1.0  # защита от деления на ноль\n",
    "\n",
    "# относительные абундансы\n",
    "wide_rel = (all_data / sample_sums)\n",
    "\n",
    "# индексы: сэмплы\n",
    "wide_rel = wide_rel.T  # теперь rows = samples, cols = taxa\n",
    "wide_rel.index.name = \"sample\"\n",
    "\n",
    "# метки классов\n",
    "def parse_class(s):\n",
    "    # ожидаем формат: class:file_stem:orig_sample\n",
    "    return s.split(\":\", 1)[0]\n",
    "\n",
    "# группа-источник (file_stem) для группового сплита\n",
    "def parse_group(s):\n",
    "    # class:file_stem:...\n",
    "    parts = s.split(\":\")\n",
    "    return parts[1] if len(parts) > 1 else \"ungrouped\"\n",
    "\n",
    "y_full = wide_rel.index.to_series().apply(parse_class)\n",
    "groups = wide_rel.index.to_series().apply(parse_group)\n",
    "\n",
    "print(\"Классы (всего):\", y_full.value_counts().to_dict())\n",
    "print(\"Групп (file_stem):\", len(groups.unique()))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f3d525e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (478, 12089)  Test shape: (120, 12089)\n",
      "Train class counts: {'forest': 160, 'grassland': 85, 'desert': 79, 'agricultural': 77, 'tropical_rainforest': 77}\n",
      "Test  class counts: {'forest': 40, 'agricultural': 23, 'tropical_rainforest': 23, 'desert': 19, 'grassland': 15}\n"
     ]
    }
   ],
   "source": [
    "use_groups = True  # если хочешь без групп — поставь False\n",
    "\n",
    "if use_groups:\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    tr_idx, te_idx = next(gss.split(wide_rel, y_full, groups=groups))\n",
    "else:\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    tr_idx, te_idx = next(sss.split(wide_rel, y_full))\n",
    "\n",
    "X_train0 = wide_rel.iloc[tr_idx].copy()\n",
    "X_test0  = wide_rel.iloc[te_idx].copy()\n",
    "y_train0 = y_full.iloc[tr_idx].copy()\n",
    "y_test0  = y_full.iloc[te_idx].copy()\n",
    "\n",
    "print(\"Train shape:\", X_train0.shape, \" Test shape:\", X_test0.shape)\n",
    "print(\"Train class counts:\", y_train0.value_counts().to_dict())\n",
    "print(\"Test  class counts:\", y_test0.value_counts().to_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "45b33b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAP features: 2632\n"
     ]
    }
   ],
   "source": [
    "# prevalence по train: доля сэмплов с ненулём\n",
    "prev = (X_train0 > 0).mean(axis=0)  # по колонкам (таксонам)\n",
    "\n",
    "# средняя ненулевая относительная абунданса по train\n",
    "def nonzero_mean(col):\n",
    "    nz = col[col > 0]\n",
    "    return float(nz.mean()) if len(nz) else 0.0\n",
    "\n",
    "mean_abund = X_train0.apply(nonzero_mean, axis=0)\n",
    "\n",
    "cap_mask = (prev >= PREVALENCE_MIN) & (mean_abund >= MEAN_ABUND_MIN)\n",
    "cap_features = mean_abund[cap_mask].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "if len(cap_features) > CAP_MAX_FEATURES:\n",
    "    cap_features = cap_features[:CAP_MAX_FEATURES]\n",
    "\n",
    "print(f\"CAP features: {len(cap_features)}\")\n",
    "\n",
    "X_tr = X_train0[cap_features].copy()\n",
    "X_te = X_test0[cap_features].copy()\n",
    "y_tr = y_train0.copy()\n",
    "y_te = y_test0.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66b9f270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool after per-class selection: 934\n",
      "Chosen features: 934\n"
     ]
    }
   ],
   "source": [
    "# 1) доля встречаемости внутри каждого класса по train\n",
    "class_pools = []\n",
    "for cls in sorted(y_tr.unique()):\n",
    "    cls_mask = (y_tr == cls)\n",
    "    X_cls = X_tr.loc[cls_mask]\n",
    "    prev_cls = (X_cls > 0).mean(axis=0)\n",
    "    # отберём по порогу и отсортируем по средней ненулевой абундансе\n",
    "    nnz_mean_cls = X_cls.apply(lambda c: c[c > 0].mean() if (c > 0).any() else 0.0, axis=0)\n",
    "    mask_cls = prev_cls >= MIN_CLASS_PREV\n",
    "    feats_cls = nnz_mean_cls[mask_cls].sort_values(ascending=False).index.tolist()\n",
    "    feats_cls = feats_cls[:TOP_PER_CLASS]\n",
    "    class_pools.extend(feats_cls)\n",
    "\n",
    "pool = sorted(set(class_pools))\n",
    "print(f\"Pool after per-class selection: {len(pool)}\")\n",
    "\n",
    "X_tr_pool = X_tr[pool].copy()\n",
    "X_te_pool = X_te[pool].copy()\n",
    "\n",
    "# 2) mutual information для ужатия до K_TOTAL — СТРОГО по train\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_tr)\n",
    "\n",
    "mi = mutual_info_classif(X_tr_pool.fillna(0.0), y_enc, random_state=RANDOM_STATE, discrete_features=False)\n",
    "mi_s = pd.Series(mi, index=X_tr_pool.columns).sort_values(ascending=False)\n",
    "\n",
    "chosen = mi_s.index[:min(K_TOTAL, len(mi_s))].tolist()\n",
    "print(\"Chosen features:\", len(chosen))\n",
    "\n",
    "X_train = X_tr_pool[chosen].fillna(0.0)\n",
    "X_test  = X_te_pool[chosen].fillna(0.0)\n",
    "y_train = y_tr.copy()\n",
    "y_test  = y_te.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f9f41bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LogReg ===\n",
      "Accuracy: 0.9750\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       agricultural     0.9583    1.0000    0.9787        23\n",
      "             desert     1.0000    1.0000    1.0000        19\n",
      "             forest     0.9756    1.0000    0.9877        40\n",
      "          grassland     1.0000    0.9333    0.9655        15\n",
      "tropical_rainforest     0.9545    0.9130    0.9333        23\n",
      "\n",
      "           accuracy                         0.9750       120\n",
      "          macro avg     0.9777    0.9693    0.9730       120\n",
      "       weighted avg     0.9752    0.9750    0.9747       120\n",
      "\n",
      "\n",
      "=== RF ===\n",
      "Accuracy: 0.9833\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       agricultural     1.0000    1.0000    1.0000        23\n",
      "             desert     1.0000    1.0000    1.0000        19\n",
      "             forest     0.9524    1.0000    0.9756        40\n",
      "          grassland     1.0000    0.9333    0.9655        15\n",
      "tropical_rainforest     1.0000    0.9565    0.9778        23\n",
      "\n",
      "           accuracy                         0.9833       120\n",
      "          macro avg     0.9905    0.9780    0.9838       120\n",
      "       weighted avg     0.9841    0.9833    0.9833       120\n",
      "\n",
      "\n",
      "=== SVMrbf ===\n",
      "Accuracy: 0.9000\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       agricultural     1.0000    1.0000    1.0000        23\n",
      "             desert     1.0000    0.6316    0.7742        19\n",
      "             forest     0.7692    1.0000    0.8696        40\n",
      "          grassland     1.0000    0.8667    0.9286        15\n",
      "tropical_rainforest     1.0000    0.8696    0.9302        23\n",
      "\n",
      "           accuracy                         0.9000       120\n",
      "          macro avg     0.9538    0.8736    0.9005       120\n",
      "       weighted avg     0.9231    0.9000    0.8985       120\n",
      "\n",
      "\n",
      "=== KNN5 ===\n",
      "Accuracy: 0.9083\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       agricultural     1.0000    1.0000    1.0000        23\n",
      "             desert     0.9500    1.0000    0.9744        19\n",
      "             forest     0.8163    1.0000    0.8989        40\n",
      "          grassland     1.0000    0.9333    0.9655        15\n",
      "tropical_rainforest     0.9286    0.5652    0.7027        23\n",
      "\n",
      "           accuracy                         0.9083       120\n",
      "          macro avg     0.9390    0.8997    0.9083       120\n",
      "       weighted avg     0.9172    0.9083    0.9009       120\n",
      "\n",
      "\n",
      "=== GBC ===\n",
      "Accuracy: 0.9667\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       agricultural     1.0000    1.0000    1.0000        23\n",
      "             desert     0.9500    1.0000    0.9744        19\n",
      "             forest     0.9744    0.9500    0.9620        40\n",
      "          grassland     0.9333    0.9333    0.9333        15\n",
      "tropical_rainforest     0.9565    0.9565    0.9565        23\n",
      "\n",
      "           accuracy                         0.9667       120\n",
      "          macro avg     0.9628    0.9680    0.9652       120\n",
      "       weighted avg     0.9669    0.9667    0.9666       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reports = {}\n",
    "\n",
    "for name, model in MODELS.items():\n",
    "    # Скейлер полезен для LogReg/SVM/KNN; для RF/GBC он не навредит,\n",
    "    # т.к. мы скейлим внутри пайплайна (fit только на train)\n",
    "    pipe = ImbPipeline(steps=[\n",
    "        (\"ros\",    RandomOverSampler(random_state=RANDOM_STATE)),\n",
    "        (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"clf\",    model)\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy:\", f\"{acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    reports[name] = acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0384f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбери лучшую модель по accuracy для примера важности\n",
    "best_name = max(reports, key=reports.get)\n",
    "best_model = MODELS[best_name]\n",
    "\n",
    "pipe_best = ImbPipeline(steps=[\n",
    "    (\"ros\",    RandomOverSampler(random_state=RANDOM_STATE)),\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\",    best_model)\n",
    "])\n",
    "\n",
    "pipe_best.fit(X_train, y_train)\n",
    "\n",
    "perm = permutation_importance(\n",
    "    pipe_best,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    n_repeats=10,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "imp = pd.Series(perm.importances_mean, index=X_test.columns).sort_values(ascending=False)\n",
    "display(imp.head(30))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
